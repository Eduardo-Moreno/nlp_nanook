{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_pickle('../../data/preprocessed/stemm_lemm_text_nanook.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Page Name', 'Facebook Id', 'Likes at Posting', 'Post Created', 'Type',\n",
       "       'Total Interactions', 'Likes', 'Comments', 'Shares', 'Love', 'Wow',\n",
       "       'Haha', 'Sad', 'Angry', 'Care', 'Message', 'Image Text', 'Link Text',\n",
       "       'Description',\n",
       "       'Overperforming Score (weighted  ‚Äî  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )',\n",
       "       'messageChar_length', 'messageWords_length', 'Message_clean',\n",
       "       'Message_clean_stemm', 'Message_clean_lemm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Name</th>\n",
       "      <th>Message</th>\n",
       "      <th>Message_clean</th>\n",
       "      <th>Message_clean_stemm</th>\n",
       "      <th>Message_clean_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AgroForestales C.A.</td>\n",
       "      <td>Mitigar el cambio clim√°tico con los pies en la...</td>\n",
       "      <td>mitigar el cambio climatico con los pies en la...</td>\n",
       "      <td>mitig el cambi climat con los pies en la tierr</td>\n",
       "      <td>mitigar el cambio climatico con el pie en el t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El Sol de San Juan del R√≠o</td>\n",
       "      <td>#M√©xico üá≤üáΩ | La Ciudad de M√©xico es la primera...</td>\n",
       "      <td>mexico   la ciudad de mexico es la primera urb...</td>\n",
       "      <td>mexic la ciud de mexic es la primer urbe en la...</td>\n",
       "      <td>mexico    el ciudad de mexico ser el primero u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V√≠ctor Quintana Silveyra</td>\n",
       "      <td>Para este 2018 que comienza les deseo de coraz...</td>\n",
       "      <td>para este 2018 que comienza les deseo de coraz...</td>\n",
       "      <td>par este 2018 que comienz les dese de corazon ...</td>\n",
       "      <td>para este 2018 que comenzar √©l desear de coraz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Webguerrillera Internacional</td>\n",
       "      <td>La ONU lanza alerta roja para 2018 por armas n...</td>\n",
       "      <td>la onu lanza alerta roja para 2018 por armas n...</td>\n",
       "      <td>la onu lanz alert roj par 2018 por armas nucle...</td>\n",
       "      <td>el onu lanzar alerta rojo para 2018 por arma n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Libertad y Pensamiento</td>\n",
       "      <td>Novedoso proyecto busca instalar paneles solar...</td>\n",
       "      <td>novedoso proyecto busca instalar paneles solar...</td>\n",
       "      <td>noved proyect busc instal panel solar en la lu...</td>\n",
       "      <td>novedoso proyecto buscar instalar panel solar ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Page Name  \\\n",
       "0           AgroForestales C.A.   \n",
       "1    El Sol de San Juan del R√≠o   \n",
       "2      V√≠ctor Quintana Silveyra   \n",
       "3  Webguerrillera Internacional   \n",
       "4        Libertad y Pensamiento   \n",
       "\n",
       "                                             Message  \\\n",
       "0  Mitigar el cambio clim√°tico con los pies en la...   \n",
       "1  #M√©xico üá≤üáΩ | La Ciudad de M√©xico es la primera...   \n",
       "2  Para este 2018 que comienza les deseo de coraz...   \n",
       "3  La ONU lanza alerta roja para 2018 por armas n...   \n",
       "4  Novedoso proyecto busca instalar paneles solar...   \n",
       "\n",
       "                                       Message_clean  \\\n",
       "0  mitigar el cambio climatico con los pies en la...   \n",
       "1  mexico   la ciudad de mexico es la primera urb...   \n",
       "2  para este 2018 que comienza les deseo de coraz...   \n",
       "3  la onu lanza alerta roja para 2018 por armas n...   \n",
       "4  novedoso proyecto busca instalar paneles solar...   \n",
       "\n",
       "                                 Message_clean_stemm  \\\n",
       "0     mitig el cambi climat con los pies en la tierr   \n",
       "1  mexic la ciud de mexic es la primer urbe en la...   \n",
       "2  par este 2018 que comienz les dese de corazon ...   \n",
       "3  la onu lanz alert roj par 2018 por armas nucle...   \n",
       "4  noved proyect busc instal panel solar en la lu...   \n",
       "\n",
       "                                  Message_clean_lemm  \n",
       "0  mitigar el cambio climatico con el pie en el t...  \n",
       "1  mexico    el ciudad de mexico ser el primero u...  \n",
       "2  para este 2018 que comenzar √©l desear de coraz...  \n",
       "3  el onu lanzar alerta rojo para 2018 por arma n...  \n",
       "4  novedoso proyecto buscar instalar panel solar ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[['Page Name', 'Message', 'Message_clean', 'Message_clean_stemm', 'Message_clean_lemm']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87422, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20415"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_clean['Facebook Id']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El set de datos consta de $87,422$ posts de Facebook realizados por $20,415$ usuarios."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que se han procesado los posts, a continuaci√≥n se muestran los posts:\n",
    "- Originales\n",
    "- Limpios (sin *stop words*)\n",
    "- *Lematizados*\n",
    "- *Stemmizados*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MESSAGE\n",
      "Post 1: Mitigar el cambio clim√°tico con los pies en la tierra. http://regenerationinternational.org/2017/12/27/agricultura-regenerativa-tierra-cambio-climatico/:=:https://regenerationinternational.org/2017/12/27/agricultura-regenerativa-tierra-cambio-climatico/\n",
      "Post 2: #M√©xico üá≤üáΩ | La Ciudad de M√©xico es la primera urbe en Latinoam√©rica que busca a la siguiente generaci√≥n de mujeres l√≠deres.\n",
      "Post 3: Para este 2018 que comienza les deseo de coraz√≥n que hagan todo lo que disfruten, pero, m√°s a√∫n, que disfruten todo lo que hagan. Que repartan amor por todos lados: A los seres humanos y a toda la comunidad de los seres vivos. Porque el terrible calentamiento global Y el a√∫n m√°s serio calentamiento social, de violencias, odios, muertes y exclusiones, s√≥lo los podemos anular si hacemos mucho m√°s densa la ‚Äúamor√≥sfera‚Äù: La gran energ√≠a del amor presente, actuante y en continua expansi√≥n. Con esa solidaridad, con ese amor universal haremos presente la esperanza este 2018. Con mucho cari√±o, Victor Quintana\n",
      "Post 4: La ONU lanza alerta roja para 2018 por armas nucleares, violaci√≥n a DH y cambio clim√°tico ‚ÄúLa unidad es el camino‚Äù, insisti√≥ el secretario. ‚ÄúNuestro futuro depende de ello‚Äù.\n",
      "Post 5: Novedoso proyecto busca instalar paneles solares en la luna, para abastecer de energ√≠a al planeta Tierra.!! https://goo.gl/c4gPQq:=:https://www.libertadypensamiento.com/2016/04/instalar-paneles-solares-luna-cambio-climatico.html\n",
      "\n",
      "\n",
      "CLEAN MESSAGE\n",
      "Post 1: mitigar el cambio climatico con los pies en la tierra \n",
      "Post 2: mexico   la ciudad de mexico es la primera urbe en latinoamerica que busca a la siguiente generacion de mujeres lideres\n",
      "Post 3: para este 2018 que comienza les deseo de corazon que hagan todo lo que disfruten pero mas aun que disfruten todo lo que hagan que repartan amor por todos lados a los seres humanos y a toda la comunidad de los seres vivos porque el terrible calentamiento global y el aun mas serio calentamiento social de violencias odios muertes y exclusiones solo los podemos anular si hacemos mucho mas densa la amorosfera la gran energia del amor presente actuante y en continua expansion con esa solidaridad con ese amor universal haremos presente la esperanza este 2018 con mucho carino victor quintana\n",
      "Post 4: la onu lanza alerta roja para 2018 por armas nucleares violacion a dh y cambio climatico la unidad es el camino insistio el secretario nuestro futuro depende de ello\n",
      "Post 5: novedoso proyecto busca instalar paneles solares en la luna para abastecer de energia al planeta tierra \n",
      "\n",
      "\n",
      "LEMMED MESSAGE\n",
      "Post 1: mitigar el cambio climatico con el pie en el tierra\n",
      "Post 2: mexico    el ciudad de mexico ser el primero urbe en latinoamerica que buscar a el siguiente generacion de mujer lider\n",
      "Post 3: para este 2018 que comenzar √©l desear de corazon que hacer todo √©l que disfrutar pero mas aun que disfrutar todo √©l que hacer que repartir amor por todo lado a el ser humano y a todo el comunidad de el ser vivo porque el terrible calentamiento global y el aun mas serio calentamiento social de violencia odio muerte y exclusi√≥n solo √©l poder anular si hacer mucho mas denso el amorosfera el gran energia del amor presente actuante y en continuo expansion con ese solidaridad con ese amor universal hacer presente el esperanza este 2018 con mucho carino victor quintana\n",
      "Post 4: el onu lanzar alerta rojo para 2018 por arma nuclear violacion a dh y cambio climatico el unidad ser el camino insistio el secretario nuestro futuro depender de √©l\n",
      "Post 5: novedoso proyecto buscar instalar panel solar en el luna para abastecer de energia al planeta tierra\n",
      "\n",
      "\n",
      "STEMMED MESSAGE\n",
      "Post 1: mitig el cambi climat con los pies en la tierr\n",
      "Post 2: mexic la ciud de mexic es la primer urbe en latinoamer que busc a la siguient gener de mujer lider\n",
      "Post 3: par este 2018 que comienz les dese de corazon que hag tod lo que disfrut per mas aun que disfrut tod lo que hag que repart amor por tod lad a los ser human y a tod la comun de los ser viv porqu el terribl calent global y el aun mas seri calent social de violenci odi muert y exclusion sol los pod anul si hac much mas dens la amorosfer la gran energi del amor present actuant y en continu expansion con esa solidar con ese amor universal har present la esper este 2018 con much carin victor quintan\n",
      "Post 4: la onu lanz alert roj par 2018 por armas nuclear violacion a dh y cambi climat la unid es el camin insisti el secretari nuestr futur depend de ello\n",
      "Post 5: noved proyect busc instal panel solar en la lun par abastec de energi al planet tierr\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('ORIGINAL MESSAGE')\n",
    "for i, text in enumerate(df_clean['Message']):\n",
    "    print(f\"Post {i + 1}: {text}\")\n",
    "    #display(Markdown(f\"Post {i + 1}: {text}\"))\n",
    "    if i == 4:\n",
    "        break\n",
    "print(\"\\n\")\n",
    "\n",
    "print('CLEAN MESSAGE')\n",
    "for i, text in enumerate(df_clean['Message_clean']):\n",
    "    print(f\"Post {i + 1}: {text}\")\n",
    "    if i == 4:\n",
    "        break\n",
    "print(\"\\n\")\n",
    "\n",
    "print('LEMMED MESSAGE')\n",
    "for i, text in enumerate(df_clean['Message_clean_lemm']):\n",
    "    print(f\"Post {i + 1}: {text}\")\n",
    "    if i == 4:\n",
    "        break\n",
    "print(\"\\n\")\n",
    "\n",
    "print('STEMMED MESSAGE')\n",
    "for i, text in enumerate(df_clean['Message_clean_stemm']):\n",
    "    print(f\"Post {i + 1}: {text}\")\n",
    "    if i == 4:\n",
    "        break\n",
    "print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar todos los posts en un archivo de texto plano (`facebook_posts.txt`) para procesarlos posteriormente con `spaCy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_FACEBOOK_POSTS_PATH_FILE = \"../../data/preprocessed/clean_posts.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 0:\n",
    "    with open(CLEAN_FACEBOOK_POSTS_PATH_FILE, \"w\") as f:\n",
    "        for i, post in enumerate(df_clean['Message_clean'].values.tolist()):\n",
    "            f.write(post + \"\\n\\n\")\n",
    "    print('Se escribireron {:,} posts de facebook en el archivo de texto plano {:}.'.format(i, CLEAN_FACEBOOK_POSTS_PATH_FILE.split('/')[-1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `spaCy`\n",
    "\n",
    "`spaCy` es una librer√≠a de Python utilizada para proyectos de **Procesamiento del Lenguaje Natural** (NLP) poniendo a la disposici√≥n del programador varias t√©cnicas utilizadas en un pipeline de NLP:\n",
    "- Tokenization\n",
    "- Normalizaci√≥n del texto (eliminar may√∫sculas, stemming, lemmatization)\n",
    "- Part-Of-Speech tagging\n",
    "- Named Entity Recognition (NER)\n",
    "\n",
    "Para instalar `spaCy` y dependencias:\n",
    "```\n",
    "pip install spacy\n",
    "\n",
    "pip install es-core-news-sm\n",
    "\n",
    "python -m spacy download es_core_news_lg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import itertools as it\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('es_core_news_sm')\n",
    "nlp = spacy.load('es_core_news_lg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostremos un posts de facebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para este 2018 que comienza les deseo de corazon que hagan todo lo que disfruten pero mas aun que disfruten todo lo que hagan que repartan amor por todos lados a los seres humanos y a toda la comunidad de los seres vivos porque el terrible calentamiento global y el aun mas serio calentamiento social de violencias odios muertes y exclusiones solo los podemos anular si hacemos mucho mas densa la amorosfera la gran energia del amor presente actuante y en continua expansion con esa solidaridad con ese amor universal haremos presente la esperanza este 2018 con mucho carino victor quintana\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with codecs.open(CLEAN_FACEBOOK_POSTS_PATH_FILE, encoding='utf_8') as f:\n",
    "    sample_review = list(it.islice(f, 4, 5))[0]\n",
    "    sample_review = sample_review.replace('\\\\n', '\\n')\n",
    "        \n",
    "print(sample_review)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora trabajemos con `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_review = nlp(sample_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para este 2018 que comienza les deseo de corazon que hagan todo lo que disfruten pero mas aun que disfruten todo lo que hagan que repartan amor por todos lados a los seres humanos y a toda la comunidad de los seres vivos porque el terrible calentamiento global y el aun mas serio calentamiento social de violencias odios muertes y exclusiones solo los podemos anular si hacemos mucho mas densa la amorosfera la gran energia del amor presente actuante y en continua expansion con esa solidaridad con ese amor universal haremos presente la esperanza este 2018 con mucho carino victor quintana\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(parsed_review)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luce id√©ntico a la cadena sin utilizar `spaCy`, ¬øcu√°l es la diferencia?\n",
    "\n",
    "Gracias a `spaCy` es f√°cil obtener la tarea de preprocesamiento (realizada con anterioridad), as√≠ como m√°s herramientas √∫tiles en **NLP**:\n",
    "- Part-of-Speech (POS)\n",
    "- Lemmatization\n",
    "- Stop words\n",
    "- Named Entity Recognition (adjetivos, sustantivos, pronombres, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_text</th>\n",
       "      <th>part_of_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>para</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>este</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>que</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comienza</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>mucho</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>carino</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>victor</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>quintana</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    token_text part_of_speech\n",
       "0         para            ADP\n",
       "1         este            DET\n",
       "2         2018           NOUN\n",
       "3          que           PRON\n",
       "4     comienza           VERB\n",
       "..         ...            ...\n",
       "97       mucho            DET\n",
       "98      carino           NOUN\n",
       "99      victor          PROPN\n",
       "100   quintana          PROPN\n",
       "101         \\n          SPACE\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_text = [token.orth_ for token in parsed_review]\n",
    "token_pos = [token.pos_ for token in parsed_review]\n",
    "\n",
    "pd.DataFrame(zip(token_text, token_pos),\n",
    "             columns=['token_text', 'part_of_speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity 1: carino victor quintana - PER\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num, entity in enumerate(parsed_review.ents):\n",
    "    print('Entity {}:'.format(num + 1), entity, '-', entity.label_)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_text</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>para</td>\n",
       "      <td>para</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>este</td>\n",
       "      <td>este</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>dddd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>que</td>\n",
       "      <td>que</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comienza</td>\n",
       "      <td>comenzar</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>mucho</td>\n",
       "      <td>mucho</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>carino</td>\n",
       "      <td>carino</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>victor</td>\n",
       "      <td>victor</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>quintana</td>\n",
       "      <td>quintana</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    token_text token_lemma token_shape\n",
       "0         para        para        xxxx\n",
       "1         este        este        xxxx\n",
       "2         2018        2018        dddd\n",
       "3          que         que         xxx\n",
       "4     comienza    comenzar        xxxx\n",
       "..         ...         ...         ...\n",
       "97       mucho       mucho        xxxx\n",
       "98      carino      carino        xxxx\n",
       "99      victor      victor        xxxx\n",
       "100   quintana    quintana        xxxx\n",
       "101         \\n          \\n          \\n\n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_lemma = [token.lemma_ for token in parsed_review]\n",
    "token_shape = [token.shape_ for token in parsed_review]\n",
    "\n",
    "pd.DataFrame(zip(token_text, token_lemma, token_shape),\n",
    "             columns=['token_text', 'token_lemma', 'token_shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "para este 2018 que comienza les deseo de corazon que hagan todo lo que disfruten pero mas aun que disfruten todo lo que hagan que repartan amor por todos lados a los seres humanos y a toda la comunidad de los seres vivos porque el terrible calentamiento global y el aun mas serio calentamiento social de violencias odios muertes y exclusiones solo los podemos anular si hacemos mucho mas densa la amorosfera la gran energia del amor presente actuante y en continua expansion con esa solidaridad con ese amor universal haremos presente la esperanza este 2018 con mucho carino victor quintana\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num, sentence in enumerate(parsed_review.sents):\n",
    "    print('Sentence {}:'.format(num + 1))\n",
    "    print(sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_text</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>inside_outside_begin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>para</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>este</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>que</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comienza</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>mucho</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>carino</td>\n",
       "      <td>PER</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>victor</td>\n",
       "      <td>PER</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>quintana</td>\n",
       "      <td>PER</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>\\n</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    token_text entity_type inside_outside_begin\n",
       "0         para                                O\n",
       "1         este                                O\n",
       "2         2018                                O\n",
       "3          que                                O\n",
       "4     comienza                                O\n",
       "..         ...         ...                  ...\n",
       "97       mucho                                O\n",
       "98      carino         PER                    B\n",
       "99      victor         PER                    I\n",
       "100   quintana         PER                    I\n",
       "101         \\n                                O\n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_entity_type = [token.ent_type_ for token in parsed_review]\n",
    "token_entity_iob = [token.ent_iob_ for token in parsed_review]\n",
    "\n",
    "pd.DataFrame(zip(token_text, token_entity_type, token_entity_iob),\n",
    "             columns=['token_text', 'entity_type', 'inside_outside_begin'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬°Una de las ventajas de trabajar con `spaCy` es que podemos preprocesar los datos **m√°s r√°pido**! Nos pudimos ahorrar el trabajo de procesamiento de texto utilizando los modelos precargados de `spaCy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/5277wsy51nj0m1lc9jvl8zt80000gn/T/ipykernel_39731/1388163201.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['Yes' 'Yes' '' 'Yes' '' 'Yes' '' 'Yes' '' 'Yes' '' 'Yes' 'Yes' 'Yes' ''\n",
      " 'Yes' 'Yes' 'Yes' 'Yes' '' 'Yes' 'Yes' 'Yes' '' 'Yes' '' '' 'Yes' 'Yes'\n",
      " '' 'Yes' 'Yes' '' '' 'Yes' 'Yes' 'Yes' 'Yes' '' 'Yes' 'Yes' '' '' 'Yes'\n",
      " 'Yes' '' '' '' 'Yes' 'Yes' 'Yes' 'Yes' '' '' '' 'Yes' '' '' '' 'Yes' ''\n",
      " 'Yes' 'Yes' 'Yes' '' 'Yes' 'Yes' 'Yes' 'Yes' '' 'Yes' '' 'Yes' 'Yes' ''\n",
      " 'Yes' '' '' '' 'Yes' 'Yes' '' '' 'Yes' 'Yes' '' 'Yes' 'Yes' '' '' '' ''\n",
      " 'Yes' '' 'Yes' '' 'Yes' 'Yes' '' '' '' '']' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, 'stop?':'number?'] = df.loc[:, 'stop?':'number?'].map(lambda x: 'Yes' if x else '')\n",
      "/var/folders/66/5277wsy51nj0m1lc9jvl8zt80000gn/T/ipykernel_39731/1388163201.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '']' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, 'stop?':'number?'] = df.loc[:, 'stop?':'number?'].map(lambda x: 'Yes' if x else '')\n",
      "/var/folders/66/5277wsy51nj0m1lc9jvl8zt80000gn/T/ipykernel_39731/1388163201.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' 'Yes']' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, 'stop?':'number?'] = df.loc[:, 'stop?':'number?'].map(lambda x: 'Yes' if x else '')\n",
      "/var/folders/66/5277wsy51nj0m1lc9jvl8zt80000gn/T/ipykernel_39731/1388163201.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['' '' 'Yes' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " 'Yes' '' '' '' '' '' '']' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, 'stop?':'number?'] = df.loc[:, 'stop?':'number?'].map(lambda x: 'Yes' if x else '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stop?</th>\n",
       "      <th>punctuation?</th>\n",
       "      <th>whitespace?</th>\n",
       "      <th>number?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>para</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>este</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>que</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comienza</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>mucho</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>carino</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>victor</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>quintana</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         text stop? punctuation? whitespace? number?\n",
       "0        para   Yes                                 \n",
       "1        este   Yes                                 \n",
       "2        2018                                    Yes\n",
       "3         que   Yes                                 \n",
       "4    comienza                                       \n",
       "..        ...   ...          ...         ...     ...\n",
       "97      mucho   Yes                                 \n",
       "98     carino                                       \n",
       "99     victor                                       \n",
       "100  quintana                                       \n",
       "101        \\n                            Yes        \n",
       "\n",
       "[102 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_attributes = [(token.orth_,\n",
    "                     token.is_stop,\n",
    "                     token.is_punct,\n",
    "                     token.is_space,\n",
    "                     token.like_num)\n",
    "                    for token in parsed_review]\n",
    "\n",
    "df = pd.DataFrame(token_attributes,\n",
    "                  columns=['text',\n",
    "                           'stop?',\n",
    "                           'punctuation?',\n",
    "                           'whitespace?',\n",
    "                           'number?',\n",
    "                           ])\n",
    "\n",
    "df.loc[:, 'stop?':'number?'] = df.loc[:, 'stop?':'number?'].map(lambda x: 'Yes' if x else '')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nanook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
